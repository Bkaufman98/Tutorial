{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome back! \n",
    "\n",
    "## Your lifted over data treaing you well? \n",
    "\n",
    "## While we may have **updated** data, we do not neccesarily have **clean** data\n",
    "- When conducting our future analyses we want the cleanest data possible -- you deserve only the best!\n",
    "## We are going to go on a **Q**uality **C**ontrol (QC) adventure together \n",
    "- Going through some standard and neccesary steps to make sure our data is in fighting shape! \n",
    "\n",
    "## **Here’s What We’ll Do:**  \n",
    "\n",
    "### **Screen for Missingness**  \n",
    "- We’ll check for missing data at both the **variant level** (e.g., specific SNPs with too much missing data) and the **individual level** (e.g., samples with too much missing data).  \n",
    "- Missing data can skew results and reduce the power of your analysis. Let’s nip this in the bud! \n",
    "\n",
    "---\n",
    "\n",
    "### **Check Hardy-Weinberg Equilibrium (HWE)**  \n",
    "- We’ll test if the variants in our dataset follow Hardy-Weinberg expectations.  \n",
    "- Deviations from HWE can indicate genotyping errors, population stratification, or other issues. It’s like a litmus test for data quality!  \n",
    "\n",
    "---\n",
    "\n",
    "### **Remove Variant Duplicates**  \n",
    "\n",
    "- Sometimes, the same variant appears multiple times in the dataset (thanks, genotyping chips!).  \n",
    "- We’ll identify and remove these duplicates to avoid redundancy and confusion. Out with the extras!  \n",
    "\n",
    "---\n",
    "### **Remove Duplicate Samples**  \n",
    "- Occasionally, the same individual might appear more than once in the dataset (oops!).  \n",
    "- We’ll detect and remove these duplicates to ensure each individual is represented only once. No clones allowed!  \n",
    "\n",
    "---\n",
    "\n",
    "### **You’ve Got This!**  \n",
    "These QC steps are like the foundation of a house—they ensure everything built on top is solid and reliable. Let’s get to it and make your data shine!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First lets gather our tools and get coded up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "from IPython.display import display\n",
    "import shutil\n",
    "from tabulate import tabulate\n",
    "import logging\n",
    "\n",
    "#Set up plink to work in jupyter notebook (Compute Canada)\n",
    "!module load StdEnv/2020 && module load plink/1.9b_6.21-x86_64 && which plink\n",
    "!module load StdEnv/2020 && module load plink/2.00a3.6 && which plink2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copy the output from above into this next command -- or just the absolute path to your downloaded plink\n",
    "plink_path = 'path/to/plink command'\n",
    "plink2_path = 'path/to/plink/command'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Shared QC table to track all studies\n",
    "shared_qc_table = []\n",
    "\n",
    "def count_variants(study_name, bim_file, fam_file, step_name):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        study_name : Name of the study (e.g., \"Study1\").\n",
    "        bim_file : Path to the BIM file.\n",
    "        fam_file : Path to the FAM file.\n",
    "        step_name : Name of the step (e.g., \"Start\", \"After Class1\", \"After Class2\").\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary containing counts for autosomal, X, Y, MT variants,\n",
    "              total individuals, males, females, and ambiguous individuals.\n",
    "    \"\"\"\n",
    "    autosomal = 0\n",
    "    x_chr = 0\n",
    "    y_chr = 0\n",
    "    mt_chr = 0\n",
    "\n",
    "    \n",
    "    with open(bim_file, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            chrom = parts[0]\n",
    "            if chrom.startswith(\"chr\"):\n",
    "                chrom_clean = chrom.replace(\"chr\", \"\")\n",
    "            else:\n",
    "                chrom_clean = chrom\n",
    "            if chrom_clean in ['X', '23', '25']:\n",
    "                x_chr += 1\n",
    "            elif chrom_clean in ['Y', '24']:\n",
    "                y_chr += 1\n",
    "            elif chrom_clean in ['MT', 'M', '26']:\n",
    "                mt_chr += 1\n",
    "            elif chrom_clean.isdigit():\n",
    "                if 1 <= int(chrom_clean) <= 22:\n",
    "                    autosomal += 1\n",
    "\n",
    "    \n",
    "    individuals = 0\n",
    "    males = 0\n",
    "    females = 0\n",
    "    ambiguous = 0\n",
    "    \n",
    "    with open(fam_file, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            sex_code = int(parts[4])\n",
    "            if sex_code == 1:\n",
    "                males += 1\n",
    "            elif sex_code == 2:\n",
    "                females += 1\n",
    "            elif sex_code == 0:\n",
    "                ambiguous += 1\n",
    "            individuals += 1\n",
    "    \n",
    "    shared_qc_table.append([\n",
    "        study_name,\n",
    "        step_name,\n",
    "        autosomal,\n",
    "        x_chr,\n",
    "        y_chr,\n",
    "        mt_chr,\n",
    "        individuals,\n",
    "        males,\n",
    "        females,\n",
    "        ambiguous,\n",
    "    ])\n",
    "    \n",
    "    return {\n",
    "        \"autosomal\": autosomal,\n",
    "        \"x_chr\": x_chr,\n",
    "        \"y_chr\": y_chr,\n",
    "        \"mt_chr\": mt_chr,\n",
    "        \"individuals\": individuals,\n",
    "        \"males\": males,\n",
    "        \"females\": females,\n",
    "        \"ambiguous\": ambiguous,\n",
    "    }\n",
    "headers = [\n",
    "    \"Study Name\", \"Step Name\", \"Autosomal\", \"X Chr\", \"Y Chr\", \"MT Chr\",\n",
    "    \"Individuals\", \"Males\", \"Females\", \"Ambiguous\"\n",
    "]\n",
    "\n",
    "def save_qc_table(filename=\"QC_results.txt\"):\n",
    "    \"\"\"\n",
    "    Saves the shared QC table to a text file.\n",
    "\n",
    "    Args:\n",
    "        filename : Name of the output file.\n",
    "    \"\"\"\n",
    "    with open(filename, \"w\") as f:\n",
    "        # Write the header\n",
    "        f.write(\"Study\\tStep\\tAutosomal\\tX_Chr\\tY_Chr\\tMT_Chr\\tIndividuals\\tMales\\tFemales\\tAmbiguous\\n\")\n",
    "        \n",
    "        # Write each row of data\n",
    "        for row in shared_qc_table:\n",
    "            f.write(\"\\t\".join(map(str, row)) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class QCPlots:\n",
    "    def __init__(self, prefix_path, chromosomes=\"\"):\n",
    "        self.prefix_path = prefix_path\n",
    "        self.chromosomes = chromosomes\n",
    "        self.working_directory = os.path.dirname(self.prefix_path)\n",
    "    def check_sex_chromosomes(self):\n",
    "       #Check if the dataset contains sex chromosomes (X and Y) and print a message.\n",
    "        \n",
    "        \n",
    "        bim_file = f\"{self.prefix_path}.bim\"\n",
    "        if not os.path.exists(bim_file):\n",
    "            raise FileNotFoundError(f\"BIM file not found: {bim_file}\")\n",
    "\n",
    "        \n",
    "        has_x = False\n",
    "        has_y = False\n",
    "\n",
    "        # Check for X and Y chromosomes\n",
    "        with open(bim_file, 'r') as f:\n",
    "            for line in f:\n",
    "                # Split the line into columns\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) < 1:\n",
    "                    continue  # Skip empty lines\n",
    "\n",
    "                # Extract the chromosome column\n",
    "                chrom = parts[0]\n",
    "\n",
    "                # Check for X chromosome representations\n",
    "                if chrom in ['chrX', 'X', '23']:\n",
    "                    has_x = True\n",
    "\n",
    "                # Check for Y chromosome representations\n",
    "                if chrom in ['chrY', 'Y', '24']:\n",
    "                    has_y = True\n",
    "\n",
    "        # Print results\n",
    "        if has_x:\n",
    "            print(\"We've got X chromosomes!\")\n",
    "        else:\n",
    "            print(\"No X chromosomes :(.\")\n",
    "\n",
    "        if has_y:\n",
    "            print(\"We've got Y chromosomes!\")\n",
    "        else:\n",
    "            print(\"No Y chromosomes :(.\")\n",
    "    def read_files(self, pattern):\n",
    "        \"\"\"Read files matching a pattern and concatenate them into a DataFrame.\"\"\"\n",
    "        files = [f for f in os.listdir(self.working_directory) if f.endswith(pattern)]\n",
    "        if not files:\n",
    "            raise FileNotFoundError(f\"No files found with pattern {pattern}\")\n",
    "        df_list = [pd.read_csv(os.path.join(self.working_directory, f), sep='\\s+') for f in files]\n",
    "        return pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "    def plot_sample_missingness(self, df, chromosome):\n",
    "        \"\"\"Plot sample missingness.\"\"\"\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        sns.scatterplot(x=1 - df['F_MISS'], y=df['IID'], color='dodgerblue')\n",
    "        plt.xlabel('Call Rate')\n",
    "        plt.yticks([])\n",
    "        plt.title(f'Sample ({chromosome}) Missingness')\n",
    "        plt.show()\n",
    "\n",
    "    def plot_variant_missingness(self, df, chromosome):\n",
    "        \"\"\"Plot variant missingness.\"\"\"\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        sns.histplot(1 - df['F_MISS'], bins=60, color='dodgerblue', kde=False)\n",
    "        plt.xlabel('Call Rate')\n",
    "        plt.title(f'Variant ({chromosome}) Missingness')\n",
    "        plt.show()\n",
    "\n",
    "    def plot_heterozygosity(self, het_df):\n",
    "        \"\"\"Plot heterozygosity rate.\"\"\"\n",
    "        init_mean_het = het_df['F'].mean()\n",
    "        init_sd_het = het_df['F'].std()\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        sns.scatterplot(x=het_df['F'], y=het_df['IID'], color='dodgerblue')\n",
    "        plt.axvline(init_mean_het, color='black')\n",
    "        plt.axvline(init_mean_het + 3 * init_sd_het, color='firebrick', linestyle='--')\n",
    "        plt.axvline(init_mean_het - 3 * init_sd_het, color='firebrick', linestyle='--')\n",
    "        plt.xlabel('F')\n",
    "        plt.yticks([])\n",
    "        plt.title('Sample Heterozygosity')\n",
    "        plt.show()\n",
    "\n",
    "    def plot_maf(self, maf_df):\n",
    "        \"\"\"Plot minor allele frequency (MAF).\"\"\"\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        sns.histplot(maf_df['MAF'], bins=60, color='dodgerblue', kde=False)\n",
    "        plt.xlabel('MAF')\n",
    "        plt.title('Minor Allele Frequency')\n",
    "        plt.show()\n",
    "\n",
    "    def plot_afs(self, freqs_df):\n",
    "        \"\"\"Plot allele frequency spectrum (AFS).\"\"\"\n",
    "        freqs_df['C1'] = pd.to_numeric(freqs_df['C1'])\n",
    "        freqs_table = freqs_df['C1'].value_counts().sort_index().head(41)\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        sns.barplot(x=freqs_table.index, y=freqs_table.values, color='dodgerblue')\n",
    "        plt.xlabel('Alternate Allele Count')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title('Allele Frequency Spectrum')\n",
    "        plt.show()\n",
    "\n",
    "    def plot_hwe(self, hwe_df):\n",
    "        \"\"\"Plot Hardy-Weinberg Equilibrium (HWE).\"\"\"\n",
    "        hwe_df = hwe_df[hwe_df['TEST'].str.contains('ALL', na=False)]\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        sns.histplot(hwe_df['P'], bins=300, color='dodgerblue', kde=False)\n",
    "        plt.xlabel('HWE p-value')\n",
    "        plt.title('Hardy-Weinberg Equilibrium')\n",
    "        plt.show()\n",
    "\n",
    "    def make_plot(self):\n",
    "        #Generate plots based on the chromosome type (all or sex chromosomes).\n",
    "        if self.chromosomes == \"sex\":\n",
    "            # Read and plot X chromosome data\n",
    "            X_ind_miss = self.read_files('X.imiss')\n",
    "            X_var_miss = self.read_files('X.lmiss')\n",
    "            X_maf = self.read_files('X.frq')\n",
    "            X_freqs = self.read_files('X.frq.counts')\n",
    "            X_hwe = self.read_files('X.hwe')\n",
    "            Y_ind_miss = self.read_files('Y.imiss')\n",
    "            Y_var_miss = self.read_files('Y.lmiss')\n",
    "\n",
    "            Y_maf = self.read_files('Y.frq')\n",
    "            Y_freqs = self.read_files('Y.frq.counts')\n",
    "            Y_hwe = self.read_files('Y.hwe')            \n",
    "\n",
    "            self.plot_sample_missingness(X_ind_miss, 'X')\n",
    "            self.plot_variant_missingness(X_var_miss, 'X')\n",
    "\n",
    "            self.plot_maf(X_maf)\n",
    "            self.plot_afs(X_freqs)\n",
    "            self.plot_hwe(X_hwe)\n",
    "            self.plot_sample_missingness(Y_ind_miss, 'Y')\n",
    "            self.plot_variant_missingness(Y_var_miss, 'Y')\n",
    "            self.plot_maf(Y_maf)\n",
    "            self.plot_afs(Y_freqs)\n",
    "            self.plot_hwe(Y_hwe)\n",
    "\n",
    "        elif self.chromosomes == \"all\":\n",
    "            # Read and plot other QC metrics for all\n",
    "            ind_miss = self.read_files('.imiss')\n",
    "            var_miss = self.read_files('.lmiss')\n",
    "            het = self.read_files('.het')\n",
    "            maf = self.read_files('.frq')\n",
    "            freqs = self.read_files('.frq.counts')\n",
    "            hwe = self.read_files('.hwe')\n",
    "\n",
    "            self.plot_sample_missingness(ind_miss, 'All')\n",
    "            self.plot_variant_missingness(var_miss, 'All')\n",
    "            self.plot_heterozygosity(het)\n",
    "            self.plot_maf(maf)\n",
    "            self.plot_afs(freqs)\n",
    "            self.plot_hwe(hwe)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Invalid chromosome type. Use 'all' or 'sex'.\")\n",
    "    def run_plink(self):\n",
    "        \"\"\"\n",
    "        What you need:\n",
    "        - self.prefix_path: Absolute path to the PLINK file prefix (e.g., '/path/to/plink/files/data').\n",
    "        - chromosomes: Type of chromosomes to plot (\"all\" or \"sex\"). Default is \"all\".\n",
    "        \"\"\"\n",
    "        # Extract the directory and prefix from the absolute path\n",
    "\n",
    "        # Create a directory for pre-QC plots\n",
    "    \n",
    "    \n",
    "        # Run PLINK commands describing certain key quality control areas\n",
    "        print(\"Running key quality control evaluations...\")\n",
    "        if self.chromosomes == \"sex\":\n",
    "            has_x = os.path.exists(f\"{self.prefix_path}.bim\") and any(\"X\" in line.split()[0] for line in open(f\"{self.prefix_path}.bim\"))\n",
    "            has_y = os.path.exists(f\"{self.prefix_path}.bim\") and any(\"Y\" in line.split()[0] for line in open(f\"{self.prefix_path}.bim\"))\n",
    "\n",
    "            if has_x:\n",
    "                subprocess.run([plink_path, '--bfile', self.prefix_path, '--chr', 'X', '--missing', '--out', f\"{self.prefix_path}_95_preQCX\"], check=True)\n",
    "                subprocess.run([plink_path, '--bfile', self.prefix_path, '--chr', 'X', '--freq', '--out', f\"{self.prefix_path}_95_preQCX\"], check=True)\n",
    "                subprocess.run([plink_path, '--bfile', self.prefix_path, '--chr', 'X', '--freq', 'counts', '--out', f\"{self.prefix_path}_95_preQCX\"], check=True)\n",
    "                subprocess.run([plink_path, '--bfile', self.prefix_path, '--chr', 'X', '--filter-females', '--hardy', '--out', f\"{self.prefix_path}_95_preQCX\"], check=True)\n",
    "            else:\n",
    "                print(\"No X chromosome found in the dataset. Skipping X chromosome processing.\")\n",
    "\n",
    "            if has_y:\n",
    "                subprocess.run([plink_path, '--bfile', self.prefix_path, '--chr', 'Y', '--filter-males' , '--missing', '--out', f\"{self.prefix_path}_95_preQCY\"], check=True)\n",
    "                subprocess.run([plink_path, '--bfile', self.prefix_path, '--chr', 'Y', '--freq', '--out', f\"{self.prefix_path}_95_preQCY\"], check=True)\n",
    "                subprocess.run([plink_path, '--bfile', self.prefix_path, '--chr', 'Y', '--freq', 'counts', '--out', f\"{self.prefix_path}_95_preQCY\"], check=True)\n",
    "                subprocess.run([plink_path, '--bfile', self.prefix_path, '--chr', 'Y', '--hardy', '--out', f\"{self.prefix_path}_95_preQCY\"], check=True)\n",
    "            else:\n",
    "                print(\"No Y chromosome found in the dataset. Skipping Y chromosome processing.\")\n",
    "\n",
    "        else:\n",
    "            subprocess.run([plink_path, '--bfile', self.prefix_path, '--missing', '--out', f\"{self.prefix_path}_95_preQC\"], check=True)\n",
    "            subprocess.run([plink_path, '--bfile', self.prefix_path, '--het', '--out', f\"{self.prefix_path}_95_preQC\"], check=True)\n",
    "            subprocess.run([plink_path, '--bfile', self.prefix_path, '--freq', '--out', f\"{self.prefix_path}_95_preQC\"], check=True)\n",
    "            subprocess.run([plink_path, '--bfile', self.prefix_path, '--freq', 'counts', '--out', f\"{self.prefix_path}_95_preQC\"], check=True)\n",
    "            subprocess.run([plink_path, '--bfile', self.prefix_path, '--hardy', '--out', f\"{self.prefix_path}_95_preQC\"], check=True)\n",
    "        \n",
    "    def generate_plots(self):\n",
    "        self.run_plink()\n",
    "        print(\"Plotting results using QCPlots...\")\n",
    "        self.make_plot()\n",
    "\n",
    "        # Clean up intermediate files\n",
    "        print(\"Cleaning up intermediate files...\")\n",
    "        intermediate_files = glob.glob(f\"{self.prefix_path}_95_preQC*\")\n",
    "        for file in intermediate_files:\n",
    "            if os.path.exists(file):\n",
    "                print(f\"Removing: {file}\")\n",
    "                os.remove(file)    \n",
    "    \n",
    "        for file in intermediate_files:\n",
    "            if os.path.exists(file):\n",
    "                print(f\"Removing: {file}\")\n",
    "                os.remove(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we need our files! So that we can get started! Be sure to go back to our last tutorial together and see where you placed that! \n",
    "---\n",
    "# First thing we are going to want to do is visualize what we are dealing with quality wise! First lets start by looking at the entirety of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add as many studies as needed! Just be sure to add them downstream!\n",
    "study1= QCPlots('prefix_path_study_1', chromosomes='all or sex')\n",
    "study2= QCPlots('prefix_path_study_2', chromosomes='all or sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study1.generate_plots()\n",
    "study2.generate_plots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# So what are we observing? Do we see any noticeable trends in your data? Keep these findings in mind as we continue along!\n",
    "- Quickly, let us check if there are sex chromosomes in your dataset! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study1.check_sex_chromosomes()\n",
    "study2.check_sex_chromosomes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If there were sex chromsomes in your dataset run this next cell and if so lets see how they stand quality wise!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study1= QCPlots('prefix_path_study_1', chromosomes='all or sex')\n",
    "study2= QCPlots('prefix_path_study_2', chromosomes='all or sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study1.generate_plots()\n",
    "study2.generate_plots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now that we have an understanding of how we're starting off, we can really dive in and begin to process our data!\n",
    " - Lets get it coded up!\n",
    "---\n",
    "\n",
    "- When we are picking out thresholds here, we are screening out variants or individuals above a given threshold (e.g., If your Mind threshold is 0.05 it will screen out an individual with a 7% overall missingness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Missingness:\n",
    "    def __init__(self, study_name, base_name, out_dir):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            study_name : Name of the study.\n",
    "            base_name : Base name of the input files (including full path, e.g., \"path/to/data_base_name\").\n",
    "            out_dir : Directory where all output files will be saved.\n",
    "        \"\"\"\n",
    "        self.study_name = study_name\n",
    "        self.base_name = base_name\n",
    "        self.out_dir = out_dir\n",
    "\n",
    "        # Create the output directory if it doesn't exist\n",
    "        os.makedirs(self.out_dir, exist_ok=True)\n",
    "\n",
    "        # Initialize current BIM and FAM files\n",
    "        self.current_base = base_name\n",
    "        self.current_bim = f\"{self.current_base}.bim\"\n",
    "        self.current_fam = f\"{self.current_base}.fam\"\n",
    "        self.intermediate_files = []\n",
    "        self.original_bim = f\"{self.current_base}.bim\"\n",
    "        self.original_base = base_name\n",
    "        self.original_fam = f\"{self.current_base}.fam\"\n",
    "        count_variants(self.study_name, self.current_bim, self.current_fam, \"Start\")\n",
    "        \n",
    "\n",
    "    def filter_all(self, geno_threshold=0.05, mind_threshold=0.05):\n",
    "        \"\"\"Filter all for missingness.\"\"\"\n",
    "        # Filter for sample missingness (all)\n",
    "        \n",
    "        all_sample_base = os.path.join(self.out_dir, f\"{os.path.basename(self.base_name)}_all_sample\")\n",
    "        subprocess.run([plink_path, '--bfile', self.current_base, '--chr', '1-22', '--geno', str(geno_threshold), '--keep-allele-order', '--make-bed', '--out', all_sample_base], check=True)\n",
    "        count_variants(self.study_name, f\"{all_sample_base}.bim\", f\"{all_sample_base}.fam\", \"Autosomal Filter missing per individual\")\n",
    "\n",
    "        # Filter for variant missingness (all)\n",
    "        all_variant_base = os.path.join(self.out_dir, f\"{os.path.basename(self.base_name)}_all_variant\")\n",
    "        subprocess.run([plink_path, '--bfile', all_sample_base, '--mind', str(mind_threshold), '--keep-allele-order', '--make-bed', '--out', all_variant_base], check=True)\n",
    "        count_variants(self.study_name, f\"{all_variant_base}.bim\", f\"{all_variant_base}.fam\", \"Autosomal Filter missing per variant\")\n",
    "\n",
    "        self.current_base = all_variant_base\n",
    "        self.current_bim = f\"{all_variant_base}.bim\"\n",
    "        self.current_fam = f\"{all_variant_base}.fam\"\n",
    "\n",
    "        self.intermediate_files.extend([\n",
    "            f\"{all_sample_base}.bed\",\n",
    "            f\"{all_sample_base}.bim\",\n",
    "            f\"{all_sample_base}.fam\",\n",
    "            f\"{all_sample_base}.log\",\n",
    "            f\"{all_variant_base}.bed\",\n",
    "            f\"{all_variant_base}.bim\",\n",
    "            f\"{all_variant_base}.fam\",\n",
    "            f\"{all_variant_base}.log\"\n",
    "        ])\n",
    "        \"\"\"Sex chromosomes (especially for older data) can be rather problematic and may need to be thrown out based on missingness (lots of gaps!) \n",
    "        so this next function will look a bit crazier to ensure we don't crash!\"\"\"\n",
    "    def filter_sex_chromosomes(self, x_mind_threshold=0.1, x_geno_threshold=0.05, y_mind_threshold=0.85, y_geno_threshold=0.25):\n",
    "       #Filter sex chromosomes (X and Y) for missingness.\n",
    "        # Check if sex chromosomes are present\n",
    "        with open(self.original_bim, 'r') as f:\n",
    "            has_x = any(line.startswith('X') or line.startswith('chrX') or line.startswith('23') or line.startswith('25') for line in f)\n",
    "            has_y = any(line.startswith('Y') or line.startswith('chrY') or line.startswith('24') for line in f)\n",
    "        \n",
    "        if has_x:\n",
    "            try:\n",
    "                # Split X chromosome into PAR and non-PAR regions\n",
    "                split_x_base = os.path.join(self.out_dir, f\"{os.path.basename(self.base_name)}_splitX\")\n",
    "                subprocess.run([plink_path, '--bfile', self.original_base, '--chr', 'X', '--split-x', 'hg38', 'no-fail', '--keep-allele-order', '--make-bed', '--out', split_x_base], check=True, timeout=600)\n",
    "                \n",
    "                count_variants(self.study_name, f\"{split_x_base}.bim\", f\"{split_x_base}.fam\", \"Split X Chromosome into PAR and non-PAR regions\")\n",
    "\n",
    "                # Filter for sample missingness (X)\n",
    "                split_x_sample_base = os.path.join(self.out_dir, f\"{os.path.basename(self.base_name)}_splitX_sample\")\n",
    "                subprocess.run([plink_path, '--bfile', split_x_base, '--mind', str(x_mind_threshold), '--keep-allele-order', '--make-bed', '--out', split_x_sample_base], check=True, timeout=600)\n",
    "                count_variants(self.study_name, f\"{split_x_sample_base}.bim\", f\"{split_x_sample_base}.fam\", \"X Chromosome Filter missing per individual\")\n",
    "\n",
    "                # Filter for variant missingness (X)\n",
    "                split_x_variant_base = os.path.join(self.out_dir, f\"{os.path.basename(self.base_name)}_splitX_variant\")\n",
    "                subprocess.run([plink_path, '--bfile', split_x_sample_base, '--geno', str(x_geno_threshold), '--keep-allele-order', '--make-bed', '--out', split_x_variant_base], check=True, timeout=600)\n",
    "                count_variants(self.study_name, f\"{split_x_variant_base}.bim\", f\"{split_x_variant_base}.fam\", \"X Chromosome Filter missing per variant\")\n",
    "                self.x_base = split_x_variant_base\n",
    "            except subprocess.CalledProcessError as e:\n",
    "                logging.error(f\"Error processing X chromosome: {e}\")\n",
    "                self.x_base = None\n",
    "                shared_qc_table.append([\n",
    "                    self.study_name,\n",
    "                    \"X Chromosome QC--failed filtering\",\n",
    "                    0, 0, 0, 0, 0, 0, 0, 0\n",
    "                    \n",
    "                ])   \n",
    "        if has_y:\n",
    "            try:\n",
    "                # Filter for sample missingness (Y)\n",
    "                y_sample_base = os.path.join(self.out_dir, f\"{os.path.basename(self.base_name)}_Y_sample\")\n",
    "                subprocess.run([plink_path, '--bfile', self.original_base, '--chr', 'Y', '--filter-males', '--mind', str(y_mind_threshold), '--keep-allele-order', '--make-bed', '--out', y_sample_base], check=True, timeout=600)\n",
    "                count_variants(self.study_name, f\"{y_sample_base}.bim\", f\"{y_sample_base}.fam\", \"Y Chromosome Filter missing per individual\")\n",
    "\n",
    "                # Filter for variant missingness (Y)\n",
    "                y_variant_base = os.path.join(self.out_dir, f\"{os.path.basename(self.base_name)}_Y_variant\")\n",
    "                subprocess.run([plink_path, '--bfile', y_sample_base, '--geno', str(y_geno_threshold), '--keep-allele-order', '--make-bed', '--out', y_variant_base], check=True, timeout=600)\n",
    "                count_variants(self.study_name, f\"{y_variant_base}.bim\", f\"{y_variant_base}.fam\", \"Y Chromosome Filter missing per variant\")\n",
    "                self.y_base = y_variant_base \n",
    "            except subprocess.CalledProcessError as e:\n",
    "                logging.error(f\"Error processing Y chromosome: {e}\")\n",
    "                self.y_base = None\n",
    "                shared_qc_table.append([\n",
    "                    self.study_name,\n",
    "                    \"Y Chromosome QC--failed filtering\",\n",
    "                    0, 0, 0, 0, 0, 0, 0, 0\n",
    "                    \n",
    "                ])   \n",
    "  \n",
    "                       \n",
    "    def get_output_files(self):\n",
    "        return (\n",
    "            self.current_base,  # Always return self.current_base\n",
    "            getattr(self, 'y_base', None),  # Return self.y_base if it exists, otherwise None\n",
    "            getattr(self, 'x_base', None)   # Return self.x_base if it exists, otherwise None\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study1_M = Missingness('Study1', 'prefix_path_study_1', 'path/to/ouput/directory')\n",
    "study2_M = Missingness('Study2', 'prefix_path_study_2', 'path/to/ouput/directory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study1_M.filter_all()\n",
    "study2_M.filter_all()\n",
    "print(tabulate(shared_qc_table, headers=headers, tablefmt=\"pretty\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study1_M.filter_sex_chromosomes()\n",
    "study2_M.filter_sex_chromosomes()\n",
    "print(tabulate(shared_qc_table, headers=headers, tablefmt=\"pretty\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How are we looking? \n",
    "    - Did you have a higher missingness than what you would expect? \n",
    "        - Losing variants is never fun but in our next sections take a look at the genotyping rate in the plink output, it should be a lot higher!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let us get the Hardy-Weinberg screenings up! \n",
    "- When we are handling the X chromosomes, we are only going to be screening the X chromsomes of biological females. \n",
    "    - Why? Because biological males only have one X chromosomes (making them hemizygous) the standard test for Hardy-Weinberg Equillibrium is thrown off.\n",
    "\n",
    "---\n",
    "\n",
    "- Now lets get this coded up, when running HWE screens we are screening for variants that are more significant than the given threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HWEProcessor:\n",
    "    def __init__(self, study_name, base_name, out_dir, x_base=\"\", y_base=\"\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            study_name : Name of the study.\n",
    "            base_name : Base name of the input files (including full path, e.g., \"path/to/data_base_name\").\n",
    "            out_dir : Directory where all output files will be saved.\n",
    "            x_base : Path to the X chromosome files (if available).\n",
    "            y_base : Path to the Y chromosome files (if available).\n",
    "        \"\"\"\n",
    "        self.study_name = study_name\n",
    "        self.base_name = base_name\n",
    "        self.out_dir = out_dir\n",
    "\n",
    "        # Create the output directory if it doesn't exist\n",
    "        os.makedirs(self.out_dir, exist_ok=True)\n",
    "\n",
    "        # Initialize current BIM and FAM files\n",
    "        self.current_base = os.path.join(self.out_dir, os.path.basename(base_name))\n",
    "        self.current_bim = f\"{self.current_base}.bim\"\n",
    "        self.current_fam = f\"{self.current_base}.fam\"\n",
    "\n",
    "        # Track sex chromosome files\n",
    "        self.x_base = x_base\n",
    "        self.y_base = y_base\n",
    "\n",
    "    def filter_all(self, hwe_threshold=1e-25):\n",
    "        \"\"\"Filter all for Hardy-Weinberg Equilibrium.\"\"\"\n",
    "        all_hwe_base = os.path.join(self.out_dir, f\"{os.path.basename(self.base_name)}_all_hwe\")\n",
    "        subprocess.run([plink_path, '--bfile', self.current_base, '--hwe', str(hwe_threshold), '--keep-allele-order', '--make-bed', '--out', all_hwe_base], check=True)\n",
    "        count_variants(self.study_name, f\"{all_hwe_base}.bim\", f\"{all_hwe_base}.fam\", \"Autosomal Hardy-Weinberg Filtering (1e-25)\")\n",
    "\n",
    "        self.current_base = all_hwe_base\n",
    "        self.current_bim = f\"{all_hwe_base}.bim\"\n",
    "        self.current_fam = f\"{all_hwe_base}.fam\"\n",
    "\n",
    "    def filter_sex_chromosomes(self, hwe_threshold=1e-25):\n",
    "        \"\"\"Filter sex chromosomes (X and Y) for Hardy-Weinberg Equilibrium.\"\"\"\n",
    "        if self.x_base:\n",
    "            # Filter X chromosome for HWE\n",
    "            # HWE can only be done on biologically female X chromosomes since biological males are naturally heterozygous!\n",
    "            x_hwe_males_base = os.path.join(self.out_dir, f\"{os.path.basename(self.base_name)}_splitX_hwe_males\")\n",
    "            subprocess.run([plink_path, '--bfile', self.x_base, '--filter-males', '--keep-allele-order', '--make-bed', '--out', x_hwe_males_base], check=True)\n",
    "\n",
    "            x_hwe_females_base = os.path.join(self.out_dir, f\"{os.path.basename(self.base_name)}_splitX_hwe_females\")\n",
    "            subprocess.run([plink_path, '--bfile', self.x_base, '--filter-females', '--hwe', str(hwe_threshold), '--keep-allele-order', '--make-bed', '--out', x_hwe_females_base], check=True)\n",
    "\n",
    "            x_hwe_base = os.path.join(self.out_dir, f\"{os.path.basename(self.base_name)}_splitX_hwe\")\n",
    "            subprocess.run([plink_path, '--bfile', x_hwe_males_base, '--bmerge', x_hwe_females_base, '--keep-allele-order', '--make-bed', '--out', x_hwe_base], check=True)\n",
    "            count_variants(self.study_name, f\"{x_hwe_base}.bim\", f\"{x_hwe_base}.fam\", \"X Chromosome Hardy-Weinberg Filtering (1e-25)\")\n",
    "\n",
    "            # Update X chromosome file\n",
    "            self.x_base = x_hwe_base\n",
    "\n",
    "        if self.y_base:\n",
    "            # Filter Y chromosome for HWE\n",
    "            y_hwe_base = os.path.join(self.out_dir, f\"{os.path.basename(self.base_name)}_Y_hwe\")\n",
    "            subprocess.run([plink_path, '--bfile', self.y_base, '--hwe', str(hwe_threshold), '--filter-males', '--keep-allele-order', '--make-bed', '--out', y_hwe_base], check=True)\n",
    "            count_variants(self.study_name, f\"{y_hwe_base}.bim\", f\"{y_hwe_base}.fam\", \"Y Chromosome Hardy-Weinberg Filtering (1e-25)\")\n",
    "\n",
    "            # Update Y chromosome file\n",
    "            self.y_base = y_hwe_base\n",
    "\n",
    "    def get_output_files(self):\n",
    "        return (\n",
    "            self.current_base,  # Always return self.current_base\n",
    "            getattr(self, 'y_base', None),  # Return self.y_base if it exists, otherwise None\n",
    "            getattr(self, 'x_base', None)   # Return self.x_base if it exists, otherwise None\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take note of your last output from the last section!\n",
    "final_base = study1_M.get_output_files()\n",
    "print(f\"Final base file: {final_base}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take note of your last output from the last section!\n",
    "final_base = study2_M.get_output_files()\n",
    "print(f\"Final base file: {final_base}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study1_H = HWEProcessor('Study1', 'prefix_path_study_1', 'path/to/ouput/directory', 'path/to/x_base_if_applicable','path/to/y_base_if_applicable - if none then delete')\n",
    "study2_H = HWEProcessor('Study2', 'prefix_path_study_2', 'path/to/ouput/directory''path/to/x_base_if_applicable','path/to/y_base_if_applicable - if none then delete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study1_H.filter_all()\n",
    "study2_H.filter_all()\n",
    "print(tabulate(shared_qc_table, headers=headers, tablefmt=\"pretty\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study1_H.filter_sex_chromosomes()\n",
    "study2_H.filter_sex_chromosomes()\n",
    "print(tabulate(shared_qc_table, headers=headers, tablefmt=\"pretty\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alright! We are making great progress eh? (This tutorial was written in Canada)\n",
    "- The majority of the human genome is in Hardy-Weinberg Equillibrium so we shoudn't encounter ***too*** many variants going the way of the Dodo\n",
    "    \n",
    "    - Now let's snuff out those duplicates!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DuplicateProcessor:\n",
    "    def __init__(self, study_name, base_name, out_dir, x_base=None, y_base=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            study_name : Name of the study.\n",
    "            base_name : Base name of the input files (including full path).\n",
    "            out_dir : Directory where all output files will be saved.\n",
    "            x_base : Path to the X chromosome files (if available).\n",
    "            y_base : Path to the Y chromosome files (if available).\n",
    "        \"\"\"\n",
    "        self.study_name = study_name\n",
    "        self.base_name = base_name\n",
    "        self.out_dir = out_dir\n",
    "\n",
    "        # Create the output directory if it doesn't exist\n",
    "        os.makedirs(self.out_dir, exist_ok=True)\n",
    "\n",
    "        # Initialize current BIM and FAM files\n",
    "        self.current_base = os.path.join(os.path.basename(base_name))\n",
    "        self.current_bim = f\"{self.current_base}.bim\"\n",
    "        self.current_fam = f\"{self.current_base}.fam\"\n",
    "\n",
    "        # Track sex chromosome files\n",
    "        self.x_base = x_base\n",
    "        self.y_base = y_base\n",
    "\n",
    "    def remove_duplicates(self):\n",
    "        \"\"\"Remove duplicates in all and sex chromosomes.\"\"\"\n",
    "        all_dup_base = os.path.join(self.out_dir, f\"{os.path.basename(self.base_name)}_dup\")\n",
    "        subprocess.run([plink_path, '--bfile', self.base_name, '--list-duplicate-vars', 'ids-only', 'suppress-first', '--out', 'temp'], check=True)\n",
    "        subprocess.run([plink_path, '--bfile', self.base_name, '--exclude', 'temp.dupvar', '--keep-allele-order', '--make-bed', '--out', all_dup_base], check=True)\n",
    "        count_variants(self.study_name, f\"{all_dup_base}.bim\", f\"{all_dup_base}.fam\", \"Duplicate SNP Removal\")\n",
    "\n",
    "        self.current_base = all_dup_base\n",
    "        self.current_bim = f\"{all_dup_base}.bim\"\n",
    "        self.current_fam = f\"{all_dup_base}.fam\"\n",
    "\n",
    "        # Remove duplicates in sex chromosomes (if present)\n",
    "        if self.x_base:\n",
    "            x_dup_base = os.path.join(self.out_dir, f\"{os.path.basename(self.base_name)}_X_dup\")\n",
    "            subprocess.run([plink_path, '--bfile', self.x_base, '--list-duplicate-vars', 'ids-only', 'suppress-first', '--out', 'temp'], check=True)\n",
    "            subprocess.run([plink_path, '--bfile', self.x_base, '--exclude', 'temp.dupvar', '--keep-allele-order', '--make-bed', '--out', x_dup_base], check=True)\n",
    "            count_variants(self.study_name, f\"{x_dup_base}.bim\", f\"{x_dup_base}.fam\", \"Duplicate SNP (X) Removal\")\n",
    "\n",
    "            self.x_base = x_dup_base\n",
    "\n",
    "        if self.y_base:\n",
    "            y_dup_base = os.path.join(self.out_dir, f\"{os.path.basename(self.base_name)}_Y_dup\")\n",
    "            subprocess.run([plink_path, '--bfile', self.y_base, '--list-duplicate-vars', 'ids-only', 'suppress-first', '--out', 'temp'], check=True)\n",
    "            subprocess.run([plink_path, '--bfile', self.y_base, '--exclude', 'temp.dupvar', '--keep-allele-order', '--make-bed', '--out', y_dup_base], check=True)\n",
    "            count_variants(self.study_name, f\"{y_dup_base}.bim\", f\"{y_dup_base}.fam\", \"Duplicate SNP (Y) Removal\")\n",
    "\n",
    "            self.y_base = y_dup_base\n",
    "\n",
    "    def merge_sex_chromosomes(self):\n",
    "        \"\"\"Merge sex chromosomes back with all.\"\"\"\n",
    "        if self.x_base and self.y_base:\n",
    "            # Merge X and Y with all\n",
    "            intermediate_base = os.path.join(self.out_dir, \"intermediate\")\n",
    "            subprocess.run([plink_path, '--bfile', self.current_base, '--bmerge', self.x_base, '--keep-allele-order', '--make-bed', '--out', intermediate_base], check=True)\n",
    "            subprocess.run([plink_path, '--bfile', intermediate_base, '--bmerge', self.y_base, '--keep-allele-order', '--make-bed', '--out', f\"{self.base_name}_merge\"], check=True)\n",
    "            count_variants(self.study_name, f\"{self.base_name}_merge.bim\", f\"{self.base_name}_merge.fam\", \"Sex Chromosome merger\")\n",
    "        elif self.x_base:\n",
    "            # Merge X with all\n",
    "            subprocess.run([plink_path, '--bfile', self.current_base, '--bmerge', self.x_base, '--keep-allele-order', '--make-bed', '--out', f\"{self.base_name}_merge\"], check=True)\n",
    "            count_variants(self.study_name, f\"{self.base_name}_merge.bim\", f\"{self.base_name}_merge.fam\", \"X but no Y Merger\")\n",
    "        elif self.y_base:\n",
    "            # Merge Y with all\n",
    "            subprocess.run([plink_path, '--bfile', self.current_base, '--bmerge', self.y_base, '--keep-allele-order', '--make-bed', '--out', f\"{self.base_name}_merge\"], check=True)\n",
    "            count_variants(self.study_name, f\"{self.base_name}_merge.bim\", f\"{self.base_name}_merge.fam\", \"No X but Y Merger\")\n",
    "        else:\n",
    "            # No sex chromosomes survived QC\n",
    "            count_variants(self.study_name, f\"{self.current_base}.bim\", f\"{self.current_base}.fam\", \"No sex chromosome survived QC\")\n",
    "    \n",
    "    def get_output_files(self):\n",
    "        return self.current_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take note of your last output from the last section!\n",
    "final_base = study1_H.get_output_files()\n",
    "print(f\"Final base file: {final_base}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take note of your last output from the last section!\n",
    "final_base = study2_H.get_output_files()\n",
    "print(f\"Final base file: {final_base}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study1_D = DuplicateProcessor('Study1', 'prefix_path_study_1', 'path/to/ouput/directory', 'path/to/x_base_if_applicable','path/to/y_base_if_applicable')\n",
    "study2_D = DuplicateProcessor('Study2', 'prefix_path_study_2', 'path/to/ouput/directory''path/to/x_base_if_applicable','path/to/y_base_if_applicable')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets start with just removing duplicate variants!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study1_D.remove_duplicates()\n",
    "study2_D.remove_duplicates()\n",
    "print(tabulate(shared_qc_table, headers=headers, tablefmt=\"pretty\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We have no need to keep our sex chromosomes seperate anymore, so let us bring those back into the fold before our final step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study1_D.merge_sex_chromosomes()\n",
    "study2_D.merge_sex_chromosomes()\n",
    "print(tabulate(shared_qc_table, headers=headers, tablefmt=\"pretty\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Last step!\n",
    "- Duplicate samples is not entirely common but it is always worth checking! \n",
    "\n",
    "---\n",
    "\n",
    "- Here we are going to screen for \"monozygotic twins\" (i.e., genetically the exact same individual) and we'll only keep the individual with more present variants\n",
    "  - If they are the exact same we will have to manually curate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TwinProcessor:\n",
    "    def __init__(self, study_name, base_name, out_dir):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            study_name : Name of the study.\n",
    "            base_name : Base name of the input files (including full path, e.g., \"path/to/data_base_name\").\n",
    "            out_dir : Directory where all output files will be saved.\n",
    "        \"\"\"\n",
    "        self.study_name = study_name\n",
    "        self.base_name = base_name\n",
    "        self.out_dir = out_dir\n",
    "\n",
    "        # Create the output directory if it doesn't exist\n",
    "        os.makedirs(self.out_dir, exist_ok=True)\n",
    "        self.intermediate_files = []\n",
    "        # Initialize current BIM and FAM files\n",
    "        self.current_base = os.path.basename(base_name)\n",
    "        self.current_bim = f\"{self.current_base}.bim\"\n",
    "        self.current_fam = f\"{self.current_base}.fam\"\n",
    "\n",
    "    def identify_twins(self):\n",
    "        # Create a temporary file for processing\n",
    "        temp_base = os.path.join(self.out_dir, \"temp\")\n",
    "        subprocess.run([plink_path, \"--bfile\", self.base_name, \"--keep-allele-order\", \"--make-bed\", \"--out\", temp_base], check=True)\n",
    "\n",
    "        # Calculate relatedness using PLINK2\n",
    "        subprocess.run([plink2_path, \"--bfile\", temp_base, \"--make-king-table\", \"--king-table-filter\", \"0.25\", \"--out\", \"relatedness\"], check=True)\n",
    "\n",
    "        # Extract twin pairs with KING coefficient > 0.354\n",
    "        with open(\"relatedness.kin0\", \"r\") as kin_file, open(\"twins.txt\", \"w\") as twins_file:\n",
    "            next(kin_file)  # Skip the header line\n",
    "            for line in kin_file:\n",
    "                fields = line.strip().split()\n",
    "                if float(fields[7]) > 0.354:  # KING coefficient in column 8\n",
    "                    twins_file.write(f\"{fields[0]} {fields[1]} {fields[2]} {fields[3]}\\n\")\n",
    "        self.intermediate_files.append(f\"{temp_base}.*\")\n",
    "        self.intermediate_files.append(\"relatedness.kin0\")\n",
    "        self.intermediate_files.append(\"twins.txt\")\n",
    "    def identify_twins(self):\n",
    "        # Create a temporary file for processing\n",
    "        temp_base = os.path.join(self.out_dir, \"temp\")\n",
    "        subprocess.run([plink_path, \"--bfile\", self.base_name, \"--keep-allele-order\", \"--make-bed\", \"--out\", temp_base], check=True)\n",
    "\n",
    "        # Calculate relatedness using PLINK2\n",
    "        subprocess.run([plink2_path, \"--bfile\", temp_base, \"--make-king-table\", \"--king-table-filter\", \"0.25\", \"--out\", \"relatedness\"], check=True)\n",
    "\n",
    "        # Create twins.txt file with a header\n",
    "        twins_file_path = os.path.join(self.out_dir, \"twins.txt\")\n",
    "        with open(twins_file_path, \"w\") as twins_file:\n",
    "            twins_file.write(\"FID1\\tIID1\\tFID2\\tIID2\\n\")  # Write header\n",
    "\n",
    "            # Extract twin pairs with KING coefficient > 0.354\n",
    "            if os.path.exists(\"relatedness.kin0\"):\n",
    "                with open(\"relatedness.kin0\", \"r\") as kin_file:\n",
    "                    next(kin_file)  # Skip the header line\n",
    "                    for line in kin_file:\n",
    "                        fields = line.strip().split()\n",
    "                        if float(fields[7]) > 0.354:  # KING coefficient in column 8\n",
    "                            twins_file.write(f\"{fields[0]}\\t{fields[1]}\\t{fields[2]}\\t{fields[3]}\\n\")\n",
    "\n",
    "        self.intermediate_files.append(f\"{temp_base}.*\")\n",
    "        self.intermediate_files.append(\"relatedness.kin0\")\n",
    "        self.intermediate_files.append(twins_file_path)\n",
    "        self.twins_file = twins_file_path\n",
    "\n",
    "    def screen_twins(self):\n",
    "        # Ensure twins.txt exists\n",
    "        if not os.path.exists(self.twins_file):\n",
    "            print(\"Twins file does not exist. Creating an empty file.\")\n",
    "            with open(self.twins_file, \"w\") as twins_file:\n",
    "                twins_file.write(\"FID1\\tIID1\\tFID2\\tIID2\\n\")  # Write header\n",
    "\n",
    "        # Run PLINK to calculate missingness\n",
    "        subprocess.run([plink_path, \"--bfile\", self.base_name, \"--missing\", \"--out\", \"missingness\"], check=True)\n",
    "\n",
    "        # Read missingness data\n",
    "        individual_variants = {}\n",
    "        if os.path.exists(\"missingness.imiss\"):\n",
    "            with open(\"missingness.imiss\", \"r\") as imiss_file:\n",
    "                next(imiss_file)  # Skip the header line\n",
    "                for line in imiss_file:\n",
    "                    fields = line.strip().split()\n",
    "                    fid, iid = fields[0], fields[1]\n",
    "                    non_missing_count = int(fields[4])\n",
    "                    individual_variants[(fid, iid)] = non_missing_count\n",
    "            self.intermediate_files.append(\"missingness.imiss\")\n",
    "\n",
    "        # Initialize lists for twins to remove and tied twins\n",
    "        twins_to_remove = []\n",
    "        twins_tied = []\n",
    "\n",
    "        # Process twins file\n",
    "        with open(self.twins_file, \"r\") as twins_file:\n",
    "            header = next(twins_file)  # Read header\n",
    "            for line in twins_file:\n",
    "                fields = line.strip().split()\n",
    "                twin1 = (fields[0], fields[1])\n",
    "                twin2 = (fields[2], fields[3])\n",
    "                if twin1 in individual_variants and twin2 in individual_variants:\n",
    "                    if individual_variants[twin1] < individual_variants[twin2]:\n",
    "                        twins_to_remove.append(twin2)\n",
    "                    elif individual_variants[twin1] > individual_variants[twin2]:\n",
    "                        twins_to_remove.append(twin1)\n",
    "                    else:\n",
    "                        twins_tied.append((twin1, twin2))\n",
    "\n",
    "        # Create twins_to_remove.txt with header\n",
    "        remove_file_path = os.path.join(self.out_dir, \"twins_to_remove.txt\")\n",
    "        with open(remove_file_path, \"w\") as remove_file:\n",
    "            remove_file.write(\"FID\\tIID\\n\")  # Write header\n",
    "            for fid, iid in twins_to_remove:\n",
    "                remove_file.write(f\"{fid}\\t{iid}\\n\")\n",
    "\n",
    "        # Create twins_tied.txt with header\n",
    "        tied_file_path = os.path.join(self.out_dir, \"twins_tied.txt\")\n",
    "        with open(tied_file_path, \"w\") as tied_file:\n",
    "            tied_file.write(header)  # Write header from twins.txt\n",
    "            for twin1, twin2 in twins_tied:\n",
    "                tied_file.write(f\"{twin1[0]}\\t{twin1[1]}\\t{twin2[0]}\\t{twin2[1]}\\n\")\n",
    "\n",
    "        self.tied = tied_file_path\n",
    "        self.remove = remove_file_path\n",
    "\n",
    "\n",
    "    def remove_twins(self):\n",
    "        \"\"\"Remove flagged twins from the dataset.\"\"\"\n",
    "        qc_base = os.path.join(self.out_dir, f\"{os.path.basename(self.base_name)}_95_QC\")\n",
    "        subprocess.run([plink_path, \"--bfile\", self.base_name, \"--remove\", self.remove, \"--keep-allele-order\", \"--make-bed\", \"--out\", qc_base], check=True)\n",
    "\n",
    "        # Update current BIM and FAM files\n",
    "        self.current_base = qc_base\n",
    "        self.current_bim = f\"{qc_base}.bim\"\n",
    "        self.current_fam = f\"{qc_base}.fam\"\n",
    "        count_variants(self.study_name, self.current_bim, self.current_fam, \"Removal of Homozygotic Twins\")\n",
    "        total_manual = subprocess.run([\"wc\", \"-l\", self.tied], capture_output=True, text=True).stdout.strip()\n",
    "        print(f\"Total number of twins needing manual curation: {total_manual}\")\n",
    "\n",
    "        # Print total number of variants\n",
    "        total_variants = subprocess.run([\"wc\", \"-l\", f\"{self.current_base}.bim\"], capture_output=True, text=True).stdout.strip()\n",
    "        print(f\"Total number of variants: {total_variants}\")\n",
    "\n",
    "        print(\"Removing intermediate files...\")\n",
    "        for pattern in self.intermediate_files:\n",
    "            for file_path in glob.glob(pattern):\n",
    "                print(f\"Removing {file_path}\")\n",
    "                try:\n",
    "                    os.remove(file_path)\n",
    "                except FileNotFoundError:\n",
    "                    print(f\"File {file_path} not found. Skipping...\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error removing {file_path}: {e}\")\n",
    "        for file_path in glob.glob(os.path.join(self.out_dir, \"*\")):\n",
    "            if \"_95_QC\" not in os.path.basename(file_path):  # Check if the file does NOT contain \"_95_QC\"\n",
    "                print(f\"Removing {file_path}\")\n",
    "                try:\n",
    "                    os.remove(file_path)\n",
    "                except FileNotFoundError:\n",
    "                    print(f\"File {file_path} not found. Skipping...\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error removing {file_path}: {e}\")\n",
    "        print(f\"You have successfully screened the data for {self.study_name}, the data is squeaky clean! Happy Hunting!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_base = study1_D.get_output_files()\n",
    "print(f\"Final base file: {final_base}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_base = study2_D.get_output_files()\n",
    "print(f\"Final base file: {final_base}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "study1_T = TwinProcessor('Study1', 'prefix_path_study_1', 'path/to/ouput/directory')\n",
    "study2_T = TwinProcessor('Study2', 'prefix_path_study_2', 'path/to/ouput/directory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study1_T.remove_twins()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Reminder! Be sure to send each study to a different output directory to avoid some issues!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study1_T.identify_twins()\n",
    "study2_T.identify_twins()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do we see any twins? If not that is ok! Still run the last cell, it'll help clean up those pesky intermediate files!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study1_T.screen_twins()\n",
    "study1_T.remove_twins()\n",
    "study2_T.screen_twins()\n",
    "study2_T.remove_twins()\n",
    "print(tabulate(shared_qc_table, headers=headers, tablefmt=\"pretty\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🎉 **You're on fire!** 🎉\n",
    "\n",
    "---\n",
    "\n",
    "### **Great job!** We have now ensured that each study in our reference panel (or each array within a single study) is at the utmost quality! \n",
    "\n",
    "---\n",
    "\n",
    "## **What’s Next?**  \n",
    "Now that we are confident that our data is as clean as possible, we can finally bring them together to form one comprehensive reference panel!\n",
    "\n",
    "**Here’s the plan:**  \n",
    "- We are going to affix suffixes to the ends of our samples for ease of backtracking\n",
    "- We are going to merge the data together solely at the intersection of variants\n",
    "- Run a manhattan plot for evidence of a batch effect between studies. \n",
    "\n",
    "---\n",
    "\n",
    "### **You’re crushing it!**  \n",
    "Head over to the next section get this data finelly merged together. See you there—keep up the fantastic work! 💪  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
